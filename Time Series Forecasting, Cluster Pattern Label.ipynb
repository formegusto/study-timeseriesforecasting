{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82014d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config Data Structure\n",
    "import IPython\n",
    "import IPython.display\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "import random as ran\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as ran\n",
    "import math\n",
    "\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "from datetime import datetime as dt\n",
    "from pymongo import MongoClient as mc\n",
    "from functools import reduce\n",
    "\n",
    "sns.set(rc={'figure.figsize': (15.7, 13.27)})\n",
    "plt.rcParams['figure.figsize'] = 15.7,13.27\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "\n",
    "mongo_uri = \"mongodb://localhost:27017\"\n",
    "client = mc(mongo_uri)\n",
    "keti_db = client.keti_pattern_recognition\n",
    "\n",
    "jungang_col = keti_db.jungang_pattern\n",
    "cluster_col = keti_db.cluster_info\n",
    "weather_col = keti_db.weather_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4618d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df, val_df, test_df,\n",
    "               label_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])\n",
    "\n",
    "def split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "  if self.label_columns is not None:\n",
    "    labels = tf.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "  # Slicing doesn't preserve static shape information, so set the shapes\n",
    "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "  return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window\n",
    "\n",
    "def plot(self, model=None, plot_col='kw (15min)', max_subplots=3):\n",
    "  inputs, labels = self.example\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  plot_col_index = self.column_indices[plot_col]\n",
    "  max_n = min(max_subplots, len(inputs))\n",
    "  for n in range(max_n):\n",
    "    plt.subplot(max_subplots, 1, n+1)\n",
    "    plt.ylabel(f'{plot_col} [normed]')\n",
    "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "             label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "    if self.label_columns:\n",
    "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "    else:\n",
    "      label_col_index = plot_col_index\n",
    "\n",
    "    if label_col_index is None:\n",
    "      continue\n",
    "\n",
    "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "    if model is not None:\n",
    "      predictions = model(inputs)\n",
    "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                  marker='X', edgecolors='k', label='Predictions',\n",
    "                  c='#ff7f0e', s=64)\n",
    "\n",
    "    if n == 0:\n",
    "      plt.legend().remove()\n",
    "\n",
    "  plt.xlabel('Time [h]')\n",
    "\n",
    "WindowGenerator.plot = plot\n",
    "\n",
    "def make_dataset(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=False,\n",
    "      batch_size=32,)\n",
    "\n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset\n",
    "\n",
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "  result = getattr(self, '_example', None)\n",
    "  if result is None:\n",
    "    # No example batch was found, so get one from the `.train` dataset\n",
    "    result = next(iter(self.test))\n",
    "    # And cache it for next time\n",
    "    self._example = result\n",
    "  return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example\n",
    "\n",
    "MAX_EPOCHS = 100\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7708ebea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy (kw 15min)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>15250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:15:00</th>\n",
       "      <td>15250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:30:00</th>\n",
       "      <td>13750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:45:00</th>\n",
       "      <td>14250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08 22:45:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08 23:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08 23:15:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08 23:30:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08 23:45:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114624 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     energy (kw 15min)\n",
       "Date Time                             \n",
       "2017-01-01 00:00:00              15250\n",
       "2017-01-01 00:15:00              15250\n",
       "2017-01-01 00:30:00              13750\n",
       "2017-01-01 00:45:00              14250\n",
       "2017-01-01 01:00:00              14000\n",
       "...                                ...\n",
       "2020-04-08 22:45:00                  0\n",
       "2020-04-08 23:00:00                  0\n",
       "2020-04-08 23:15:00                  0\n",
       "2020-04-08 23:30:00                  0\n",
       "2020-04-08 23:45:00                  0\n",
       "\n",
       "[114624 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jungang_db_cur = jungang_col.find()\n",
    "db_datas = [_ for _ in jungang_db_cur]\n",
    "\n",
    "jg_datas = pd.DataFrame(columns=['Date Time','energy (kw 15min)'])\n",
    "jg_datas['Date Time'] = [_['ttime'] for _ in db_datas]\n",
    "jg_datas['energy (kw 15min)'] = [_['energy'] for _ in db_datas]\n",
    "\n",
    "date_time = pd.to_datetime(jg_datas.pop('Date Time'),\n",
    "                          format=\"%Y-%m-%d %H:%M:%S\")\n",
    "jg_datas.index = date_time\n",
    "jg_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b634fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = jg_datas.index.get_loc(jg_datas[jg_datas['energy (kw 15min)'] == 0].index[7])\n",
    "\n",
    "jg_datas = jg_datas.iloc[:idx].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15e0655a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy (kw 15min)</th>\n",
       "      <th>week sin</th>\n",
       "      <th>week cos</th>\n",
       "      <th>year sin</th>\n",
       "      <th>year cos</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>15250</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.198782</td>\n",
       "      <td>0.980044</td>\n",
       "      <td>겨울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>14000</td>\n",
       "      <td>0.680173</td>\n",
       "      <td>-0.733052</td>\n",
       "      <td>0.199485</td>\n",
       "      <td>0.979901</td>\n",
       "      <td>겨울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>14750</td>\n",
       "      <td>0.652287</td>\n",
       "      <td>-0.757972</td>\n",
       "      <td>0.200188</td>\n",
       "      <td>0.979758</td>\n",
       "      <td>겨울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>29500</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.200891</td>\n",
       "      <td>0.979614</td>\n",
       "      <td>겨울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>15750</td>\n",
       "      <td>0.593820</td>\n",
       "      <td>-0.804598</td>\n",
       "      <td>0.201593</td>\n",
       "      <td>0.979469</td>\n",
       "      <td>겨울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 19:00:00</th>\n",
       "      <td>22500</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.999984</td>\n",
       "      <td>-0.005738</td>\n",
       "      <td>가을</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 20:00:00</th>\n",
       "      <td>19250</td>\n",
       "      <td>-0.467269</td>\n",
       "      <td>0.884115</td>\n",
       "      <td>-0.999987</td>\n",
       "      <td>-0.005021</td>\n",
       "      <td>가을</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 21:00:00</th>\n",
       "      <td>20250</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>0.900969</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>가을</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 22:00:00</th>\n",
       "      <td>19000</td>\n",
       "      <td>-0.399892</td>\n",
       "      <td>0.916562</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.003586</td>\n",
       "      <td>가을</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 23:00:00</th>\n",
       "      <td>18250</td>\n",
       "      <td>-0.365341</td>\n",
       "      <td>0.930874</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.002869</td>\n",
       "      <td>가을</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15048 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     energy (kw 15min)  week sin  week cos  year sin  \\\n",
       "Date Time                                                              \n",
       "2017-01-01 00:00:00              15250  0.707107 -0.707107  0.198782   \n",
       "2017-01-01 01:00:00              14000  0.680173 -0.733052  0.199485   \n",
       "2017-01-01 02:00:00              14750  0.652287 -0.757972  0.200188   \n",
       "2017-01-01 03:00:00              29500  0.623490 -0.781831  0.200891   \n",
       "2017-01-01 04:00:00              15750  0.593820 -0.804598  0.201593   \n",
       "...                                ...       ...       ...       ...   \n",
       "2018-09-19 19:00:00              22500 -0.500000  0.866025 -0.999984   \n",
       "2018-09-19 20:00:00              19250 -0.467269  0.884115 -0.999987   \n",
       "2018-09-19 21:00:00              20250 -0.433884  0.900969 -0.999991   \n",
       "2018-09-19 22:00:00              19000 -0.399892  0.916562 -0.999994   \n",
       "2018-09-19 23:00:00              18250 -0.365341  0.930874 -0.999996   \n",
       "\n",
       "                     year cos season  \n",
       "Date Time                             \n",
       "2017-01-01 00:00:00  0.980044     겨울  \n",
       "2017-01-01 01:00:00  0.979901     겨울  \n",
       "2017-01-01 02:00:00  0.979758     겨울  \n",
       "2017-01-01 03:00:00  0.979614     겨울  \n",
       "2017-01-01 04:00:00  0.979469     겨울  \n",
       "...                       ...    ...  \n",
       "2018-09-19 19:00:00 -0.005738     가을  \n",
       "2018-09-19 20:00:00 -0.005021     가을  \n",
       "2018-09-19 21:00:00 -0.004304     가을  \n",
       "2018-09-19 22:00:00 -0.003586     가을  \n",
       "2018-09-19 23:00:00 -0.002869     가을  \n",
       "\n",
       "[15048 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_sin(ts, target_value):\n",
    "    return np.sin(ts * (2 * np.pi / target_value)).values\n",
    "def calc_cos(ts, target_value):\n",
    "    return np.cos(ts * (2 * np.pi / target_value)).values\n",
    "def get_season(month):\n",
    "    if month in [3,4,5]:\n",
    "        return \"봄\"\n",
    "    elif month in [6,7,8]:\n",
    "        return \"여름\"\n",
    "    elif month in [9,10,11]:\n",
    "        return \"가을\"\n",
    "    else:\n",
    "        return \"겨울\"\n",
    "\n",
    "# ~ 2018 year data parsing\n",
    "jg_datas = jg_datas[jg_datas.index.year <= 2018]\n",
    "date_time = jg_datas.index\n",
    "timestamp = date_time.map(dt.timestamp)\n",
    "\n",
    "day = 24 * 60 * 60\n",
    "week = 7 * day\n",
    "year = (365) * day\n",
    "\n",
    "jg_datas['week sin'] = calc_sin(timestamp, week)\n",
    "jg_datas['week cos'] = calc_cos(timestamp, week)\n",
    "jg_datas['year sin'] = calc_sin(timestamp, year)\n",
    "jg_datas['year cos'] = calc_cos(timestamp, year)\n",
    "jg_datas['season'] = [get_season(_.month) for _ in jg_datas.index]\n",
    "\n",
    "jg_datas = jg_datas[::4]\n",
    "jg_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89615798",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_1_size = 24\n",
    "year_half_size = day_1_size * int(365 / 4) \n",
    "year_1_size = day_1_size * 365\n",
    "\n",
    "training_datas = jg_datas[:year_1_size]\n",
    "validation_datas = jg_datas[year_1_size:\n",
    "                        year_1_size + year_half_size]\n",
    "testing_datas = jg_datas[year_1_size + year_half_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e999448",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = dict()\n",
    "train_type = ['univariate', 'multivariate', 'season univariate', 'season multivariate']\n",
    "uni_columns = ['energy (kw 15min)']\n",
    "mul_columns = ['energy (kw 15min)', 'week sin', 'week cos', 'year sin', 'year cos']\n",
    "seasons = [\"봄\", \"여름\", \"가을\", \"겨울\"]\n",
    "\n",
    "for t_type in train_type:\n",
    "    if 'season' in t_type:\n",
    "        seasons_dict = dict()\n",
    "        for season in seasons:\n",
    "            season_dict = dict()\n",
    "            in_col = mul_columns if \"multivariate\" in t_type else uni_columns\n",
    "            \n",
    "            season_dict['train'] = training_datas[in_col][training_datas['season'] == season].copy()\n",
    "            season_dict['val'] = validation_datas[in_col].copy()\n",
    "            season_dict['test'] = testing_datas[in_col].copy()\n",
    "            \n",
    "            seasons_dict[season] = season_dict\n",
    "        all_dict[t_type] = seasons_dict\n",
    "    else:\n",
    "        in_dict = dict()\n",
    "        in_col = mul_columns if \"multivariate\" in t_type else uni_columns\n",
    "        \n",
    "        in_dict['train'] = training_datas[in_col].copy()\n",
    "        in_dict['val'] = validation_datas[in_col].copy()\n",
    "        in_dict['test'] = testing_datas[in_col].copy()\n",
    "        \n",
    "        all_dict[t_type] = in_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b59f2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_all_dict = dict()\n",
    "\n",
    "mean = training_datas[mul_columns].mean()\n",
    "std = training_datas[mul_columns].std()\n",
    "\n",
    "for key in all_dict.keys():\n",
    "    in_col = mul_columns if \"multivariate\" in key else uni_columns\n",
    "    in_dict = all_dict[key].copy()\n",
    "    m = mean[in_col]\n",
    "    s = std[in_col]\n",
    "    \n",
    "    if \"season\" in key:\n",
    "        for season in seasons:\n",
    "            train = in_dict[season]['train'].copy()\n",
    "            val = in_dict[season]['val'].copy()\n",
    "            test = in_dict[season]['test'].copy()\n",
    "            \n",
    "            in_dict[season]['train'] = (train - m) / s\n",
    "            in_dict[season]['val'] = (val - m) / s\n",
    "            in_dict[season]['test'] = (test - m) / s\n",
    "    else:\n",
    "        train = in_dict['train'].copy()\n",
    "        val = in_dict['val'].copy()\n",
    "        test = in_dict['test'].copy()\n",
    "        \n",
    "        in_dict['train'] = (train - m) / s\n",
    "        in_dict['val'] = (val - m) / s\n",
    "        in_dict['test'] = (test - m) / s\n",
    "        \n",
    "    norm_all_dict[key] = in_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18f0d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = dict()\n",
    "\n",
    "for key in norm_all_dict.keys():\n",
    "    nad = norm_all_dict[key]\n",
    "    \n",
    "    if \"season\" in key:\n",
    "        seasons_window = dict()\n",
    "        for season in seasons:\n",
    "            season_window = dict()\n",
    "            for WINDOW_WIDTH in range(3, 21):\n",
    "                h_key = \"{} hours\".format(WINDOW_WIDTH)\n",
    "                season_window[h_key] = WindowGenerator(\n",
    "                        input_width=WINDOW_WIDTH,\n",
    "                        label_width=1,\n",
    "                        shift=1,\n",
    "                        label_columns=uni_columns,\n",
    "                        train_df=nad[season]['train'],\n",
    "                        val_df=nad[season]['val'],\n",
    "                        test_df=nad[season]['test']\n",
    "                    )\n",
    "            seasons_window[season] = season_window\n",
    "        windows[key] = seasons_window\n",
    "    else:\n",
    "        window = dict()\n",
    "        for WINDOW_WIDTH in range(3, 21):\n",
    "            h_key = \"{} hours\".format(WINDOW_WIDTH)\n",
    "            window[h_key] = WindowGenerator(\n",
    "                        input_width=WINDOW_WIDTH,\n",
    "                        label_width=1,\n",
    "                        shift=1,\n",
    "                        label_columns=uni_columns,\n",
    "                        train_df=nad['train'],\n",
    "                        val_df=nad['val'],\n",
    "                        test_df=nad['test']\n",
    "                    )\n",
    "        windows[key] = window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "552e3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_cluster_result = cluster_col.find({\n",
    "    \"uid\": \"jungang_pattern\"\n",
    "})\n",
    "cluster_result = dict()\n",
    "\n",
    "for data in cur_cluster_result:\n",
    "    in_dict = pd.DataFrame(columns=['Label', 'Weekday'])\n",
    "    in_dict.index.name = \"Date Time\"\n",
    "    \n",
    "    season = data['season']\n",
    "    infos = data['info']\n",
    "    \n",
    "    dtime = [dt.strptime(_['date'], \"%Y-%m-%d\") for _ in infos]\n",
    "    labels = [_['label'] for _ in infos]\n",
    "\n",
    "    for idx, _ in enumerate(dtime):\n",
    "        label = labels[idx]        \n",
    "        in_dict.loc[_] = [label, _.weekday()]\n",
    "        \n",
    "    cluster_result[season] = in_dict\n",
    "    \n",
    "cluster_pattern_dict = dict()\n",
    "\n",
    "for season in seasons:\n",
    "    result = cluster_result[season]\n",
    "    in_dict = pd.DataFrame(columns=[_ for _ in range(0, 24)])\n",
    "    in_dict.index.name = \"Label\"\n",
    "    \n",
    "    labels = list(set(result['Label']))\n",
    "    for label in labels:\n",
    "        cluster_pattern = np.array([])\n",
    "        date_in_labels = result[result['Label'] == label].index\n",
    "        for date in date_in_labels:\n",
    "            idx = jg_datas.index.get_loc(date)\n",
    "            pattern = jg_datas.iloc[idx: idx+24]['energy (kw 15min)'].values\n",
    "            cluster_pattern = np.append(cluster_pattern, pattern)\n",
    "        cluster_pattern = cluster_pattern.reshape(-1,24).mean(axis=0)\n",
    "        in_dict.loc[label] = cluster_pattern\n",
    "        \n",
    "    cluster_pattern_dict[season] = in_dict\n",
    "\n",
    "cluster_norm_dict = dict()\n",
    "\n",
    "mean = all_dict['univariate']['train'].mean().values[0]\n",
    "std = all_dict['univariate']['train'].std().values[0]\n",
    "\n",
    "for key in cluster_pattern_dict.keys():\n",
    "    cluster_norm_dict[key] = ((cluster_pattern_dict[key] - mean) / std).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1041dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dist_dict = dict()\n",
    "for season in cluster_result.keys():\n",
    "    cluster_season_dict = dict()\n",
    "    week_list = set(cluster_result[season]['Weekday'])\n",
    "    for week in week_list:\n",
    "        week_dist = cluster_result[season][\n",
    "            cluster_result[season]['Weekday'] == week\n",
    "        ]['Weekday'].groupby(cluster_result[season]['Label']).count().sort_values(ascending=False)\n",
    "        week_top_label = week_dist.index[0]\n",
    "        \n",
    "        cluster_season_dict[week] = week_top_label\n",
    "    cluster_dist_dict[season] = cluster_season_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f80a9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Df is Only Train Df\n",
    "class ClusterWindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df, val_df, test_df, cluster_df,\n",
    "               label_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "    self.cluster_df = cluster_df\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}',\n",
    "        f'Column indices: {self.column_indices}'])\n",
    "\n",
    "def split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "\n",
    "  if self.label_columns is not None:\n",
    "    labels = tf.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "  # Slicing doesn't preserve static shape information, so set the shapes\n",
    "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "    \n",
    "  return inputs, labels\n",
    "\n",
    "def cluster_split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "    \n",
    "  return inputs, labels\n",
    "\n",
    "def cluster_split_window_2(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "\n",
    "  if self.label_columns is not None:\n",
    "    labels = tf.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "  # Slicing doesn't preserve static shape information, so set the shapes\n",
    "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "    \n",
    "  return labels\n",
    "\n",
    "ClusterWindowGenerator.split_window = split_window\n",
    "ClusterWindowGenerator.cluster_split_window = cluster_split_window\n",
    "ClusterWindowGenerator.cluster_split_window_2 = cluster_split_window_2\n",
    "\n",
    "def plot(self, model=None, plot_col='kw (15min)', max_subplots=3):\n",
    "  inputs, labels = self.example\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  plot_col_index = self.column_indices[plot_col]\n",
    "  max_n = min(max_subplots, len(inputs))\n",
    "  for n in range(max_n):\n",
    "    plt.subplot(max_subplots, 1, n+1)\n",
    "    plt.ylabel(f'{plot_col} [normed]')\n",
    "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "             label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "    if self.label_columns:\n",
    "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "    else:\n",
    "      label_col_index = plot_col_index\n",
    "\n",
    "    if label_col_index is None:\n",
    "      continue\n",
    "\n",
    "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "    if model is not None:\n",
    "      predictions = model(inputs)\n",
    "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                  marker='X', edgecolors='k', label='Predictions',\n",
    "                  c='#ff7f0e', s=64)\n",
    "\n",
    "    if n == 0:\n",
    "      plt.legend().remove()\n",
    "\n",
    "  plt.xlabel('Time [h]')\n",
    "\n",
    "ClusterWindowGenerator.plot = plot\n",
    "\n",
    "def make_dataset(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=False,\n",
    "      batch_size=32,)\n",
    "\n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "def make_cluster_dataset(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=False,\n",
    "      batch_size=32,)\n",
    "\n",
    "  ds = ds.map(self.cluster_split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "def make_cluster_dataset_2(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=False,\n",
    "      batch_size=32,)\n",
    "\n",
    "  ds = ds.map(self.cluster_split_window_2)\n",
    "\n",
    "  return ds\n",
    "\n",
    "ClusterWindowGenerator.make_dataset = make_dataset\n",
    "ClusterWindowGenerator.make_cluster_dataset = make_cluster_dataset\n",
    "ClusterWindowGenerator.make_cluster_dataset_2 = make_cluster_dataset_2\n",
    "\n",
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def train_with_cluster(self):\n",
    "  return self.make_cluster_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def train_with_cluster_label(self):\n",
    "  return self.make_cluster_dataset_2(self.cluster_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def cluster(self):\n",
    "  return self.make_dataset(self.cluster_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "  result = getattr(self, '_example', None)\n",
    "  if result is None:\n",
    "    # No example batch was found, so get one from the `.train` dataset\n",
    "    result = next(iter(self.test))\n",
    "    # And cache it for next time\n",
    "    self._example = result\n",
    "  return result\n",
    "\n",
    "ClusterWindowGenerator.train = train\n",
    "ClusterWindowGenerator.train_with_cluster = train_with_cluster\n",
    "ClusterWindowGenerator.train_with_cluster_label = train_with_cluster_label\n",
    "ClusterWindowGenerator.cluster = cluster\n",
    "ClusterWindowGenerator.val = val\n",
    "ClusterWindowGenerator.test = test\n",
    "ClusterWindowGenerator.example = example\n",
    "\n",
    "MAX_EPOCHS = 100\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "#                 optimizer=tf.optimizers.Adam(),\n",
    "                optimizer=tf.keras.optimizers.Nadam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "  return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d83c018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nad = norm_all_dict['univariate']\n",
    "\n",
    "cluster_time_series = pd.DataFrame(columns=['energy (kw 15min)'])\n",
    "train_df = nad['train'].copy()\n",
    "for idx in range(0,len(train_df), 24):\n",
    "    in_pd = pd.DataFrame(columns=['energy (kw 15min)'])\n",
    "    index = train_df.iloc[idx: idx+24].index\n",
    "    \n",
    "    season = get_season(index[0].month)\n",
    "    weekday = index[0].weekday()\n",
    "    label = cluster_dist_dict[season][weekday]\n",
    "    c_pattern = cluster_norm_dict[season].iloc[label].values\n",
    "    \n",
    "    for idx, _ in enumerate(index):\n",
    "        in_pd.loc[_] = c_pattern[idx]\n",
    "        \n",
    "    cluster_time_series = pd.concat([cluster_time_series, in_pd])\n",
    "    \n",
    "nad['train']['cluster energy'] = cluster_time_series['energy (kw 15min)']\n",
    "nad['train']\n",
    "\n",
    "cluster_time_series = pd.DataFrame(columns=['energy (kw 15min)'])\n",
    "val_df = nad['val'].copy()\n",
    "for idx in range(0,len(val_df), 24):\n",
    "    in_pd = pd.DataFrame(columns=['energy (kw 15min)'])\n",
    "    index = val_df.iloc[idx: idx+24].index\n",
    "    \n",
    "    season = get_season(index[0].month)\n",
    "    weekday = index[0].weekday()\n",
    "    label = cluster_dist_dict[season][weekday]\n",
    "    c_pattern = cluster_norm_dict[season].iloc[label].values\n",
    "    \n",
    "    for idx, _ in enumerate(index):\n",
    "        in_pd.loc[_] = c_pattern[idx]\n",
    "        \n",
    "    cluster_time_series = pd.concat([cluster_time_series, in_pd])\n",
    "    \n",
    "nad['val']['cluster energy'] = cluster_time_series['energy (kw 15min)']\n",
    "nad['val']\n",
    "\n",
    "\n",
    "cw = WindowGenerator(\n",
    "    input_width=3,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    label_columns=uni_columns,\n",
    "    train_df=nad['train'],\n",
    "    val_df=nad['val'],\n",
    "    test_df=nad['test'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "499c8861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy (kw 15min)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>-0.265263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>-0.353558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>-0.438414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00</th>\n",
       "      <td>-0.103579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:00</th>\n",
       "      <td>-0.141419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 19:00:00</th>\n",
       "      <td>0.203648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 20:00:00</th>\n",
       "      <td>0.118969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 21:00:00</th>\n",
       "      <td>0.085097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 22:00:00</th>\n",
       "      <td>-0.359468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 23:00:00</th>\n",
       "      <td>-0.626207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2184 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     energy (kw 15min)\n",
       "2018-01-01 00:00:00          -0.265263\n",
       "2018-01-01 01:00:00          -0.353558\n",
       "2018-01-01 02:00:00          -0.438414\n",
       "2018-01-01 03:00:00          -0.103579\n",
       "2018-01-01 04:00:00          -0.141419\n",
       "...                                ...\n",
       "2018-04-01 19:00:00           0.203648\n",
       "2018-04-01 20:00:00           0.118969\n",
       "2018-04-01 21:00:00           0.085097\n",
       "2018-04-01 22:00:00          -0.359468\n",
       "2018-04-01 23:00:00          -0.626207\n",
       "\n",
       "[2184 rows x 1 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a3853aef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "274/274 [==============================] - 3s 4ms/step - loss: 0.4113 - mean_absolute_error: 0.4875 - val_loss: 0.2909 - val_mean_absolute_error: 0.4010\n",
      "Epoch 2/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.2274 - mean_absolute_error: 0.3519 - val_loss: 0.2544 - val_mean_absolute_error: 0.3541\n",
      "Epoch 3/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.2127 - mean_absolute_error: 0.3359 - val_loss: 0.2386 - val_mean_absolute_error: 0.3303\n",
      "Epoch 4/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.2093 - mean_absolute_error: 0.3318 - val_loss: 0.2303 - val_mean_absolute_error: 0.3162\n",
      "Epoch 5/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.2066 - mean_absolute_error: 0.3288 - val_loss: 0.2255 - val_mean_absolute_error: 0.3080\n",
      "Epoch 6/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.2041 - mean_absolute_error: 0.3261 - val_loss: 0.2221 - val_mean_absolute_error: 0.3039\n",
      "Epoch 7/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.2019 - mean_absolute_error: 0.3238 - val_loss: 0.2193 - val_mean_absolute_error: 0.3018\n",
      "Epoch 8/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1999 - mean_absolute_error: 0.3219 - val_loss: 0.2168 - val_mean_absolute_error: 0.3006\n",
      "Epoch 9/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1982 - mean_absolute_error: 0.3202 - val_loss: 0.2145 - val_mean_absolute_error: 0.2999\n",
      "Epoch 10/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1967 - mean_absolute_error: 0.3188 - val_loss: 0.2125 - val_mean_absolute_error: 0.2989\n",
      "Epoch 11/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1954 - mean_absolute_error: 0.3174 - val_loss: 0.2108 - val_mean_absolute_error: 0.2974\n",
      "Epoch 12/100\n",
      "274/274 [==============================] - 1s 2ms/step - loss: 0.1939 - mean_absolute_error: 0.3159 - val_loss: 0.2092 - val_mean_absolute_error: 0.2954\n",
      "Epoch 13/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1923 - mean_absolute_error: 0.3141 - val_loss: 0.2080 - val_mean_absolute_error: 0.2929\n",
      "Epoch 14/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1907 - mean_absolute_error: 0.3122 - val_loss: 0.2070 - val_mean_absolute_error: 0.2906\n",
      "Epoch 15/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1892 - mean_absolute_error: 0.3106 - val_loss: 0.2065 - val_mean_absolute_error: 0.2892\n",
      "Epoch 16/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1881 - mean_absolute_error: 0.3096 - val_loss: 0.2060 - val_mean_absolute_error: 0.2886\n",
      "Epoch 17/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1875 - mean_absolute_error: 0.3090 - val_loss: 0.2055 - val_mean_absolute_error: 0.2883\n",
      "Epoch 18/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1870 - mean_absolute_error: 0.3086 - val_loss: 0.2051 - val_mean_absolute_error: 0.2881\n",
      "Epoch 19/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1866 - mean_absolute_error: 0.3083 - val_loss: 0.2046 - val_mean_absolute_error: 0.2879\n",
      "Epoch 20/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1863 - mean_absolute_error: 0.3081 - val_loss: 0.2042 - val_mean_absolute_error: 0.2877\n",
      "Epoch 21/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1860 - mean_absolute_error: 0.3078 - val_loss: 0.2038 - val_mean_absolute_error: 0.2875\n",
      "Epoch 22/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1858 - mean_absolute_error: 0.3076 - val_loss: 0.2034 - val_mean_absolute_error: 0.2874\n",
      "Epoch 23/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1855 - mean_absolute_error: 0.3074 - val_loss: 0.2030 - val_mean_absolute_error: 0.2872\n",
      "Epoch 24/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1853 - mean_absolute_error: 0.3072 - val_loss: 0.2026 - val_mean_absolute_error: 0.2871\n",
      "Epoch 25/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1850 - mean_absolute_error: 0.3071 - val_loss: 0.2022 - val_mean_absolute_error: 0.2870\n",
      "Epoch 26/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1848 - mean_absolute_error: 0.3069 - val_loss: 0.2018 - val_mean_absolute_error: 0.2869\n",
      "Epoch 27/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1846 - mean_absolute_error: 0.3067 - val_loss: 0.2014 - val_mean_absolute_error: 0.2868\n",
      "Epoch 28/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1844 - mean_absolute_error: 0.3065 - val_loss: 0.2010 - val_mean_absolute_error: 0.2868\n",
      "Epoch 29/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1842 - mean_absolute_error: 0.3064 - val_loss: 0.2006 - val_mean_absolute_error: 0.2869\n",
      "Epoch 30/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1840 - mean_absolute_error: 0.3062 - val_loss: 0.2003 - val_mean_absolute_error: 0.2869\n",
      "Epoch 31/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1838 - mean_absolute_error: 0.3060 - val_loss: 0.1999 - val_mean_absolute_error: 0.2870\n",
      "Epoch 32/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1836 - mean_absolute_error: 0.3059 - val_loss: 0.1995 - val_mean_absolute_error: 0.2872\n",
      "Epoch 33/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1834 - mean_absolute_error: 0.3057 - val_loss: 0.1992 - val_mean_absolute_error: 0.2873\n",
      "Epoch 34/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1832 - mean_absolute_error: 0.3055 - val_loss: 0.1988 - val_mean_absolute_error: 0.2875\n",
      "Epoch 35/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1830 - mean_absolute_error: 0.3054 - val_loss: 0.1984 - val_mean_absolute_error: 0.2876\n",
      "Epoch 36/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1828 - mean_absolute_error: 0.3052 - val_loss: 0.1980 - val_mean_absolute_error: 0.2877\n",
      "Epoch 37/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1826 - mean_absolute_error: 0.3050 - val_loss: 0.1976 - val_mean_absolute_error: 0.2879\n",
      "Epoch 38/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1824 - mean_absolute_error: 0.3048 - val_loss: 0.1972 - val_mean_absolute_error: 0.2880\n",
      "Epoch 39/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1823 - mean_absolute_error: 0.3046 - val_loss: 0.1968 - val_mean_absolute_error: 0.2881\n",
      "Epoch 40/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1821 - mean_absolute_error: 0.3045 - val_loss: 0.1964 - val_mean_absolute_error: 0.2881\n",
      "Epoch 41/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1819 - mean_absolute_error: 0.3043 - val_loss: 0.1960 - val_mean_absolute_error: 0.2881\n",
      "Epoch 42/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1817 - mean_absolute_error: 0.3041 - val_loss: 0.1956 - val_mean_absolute_error: 0.2881\n",
      "Epoch 43/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1816 - mean_absolute_error: 0.3039 - val_loss: 0.1952 - val_mean_absolute_error: 0.2881\n",
      "Epoch 44/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1814 - mean_absolute_error: 0.3038 - val_loss: 0.1948 - val_mean_absolute_error: 0.2881\n",
      "Epoch 45/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1812 - mean_absolute_error: 0.3036 - val_loss: 0.1945 - val_mean_absolute_error: 0.2880\n",
      "Epoch 46/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1811 - mean_absolute_error: 0.3034 - val_loss: 0.1941 - val_mean_absolute_error: 0.2880\n",
      "Epoch 47/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1810 - mean_absolute_error: 0.3033 - val_loss: 0.1938 - val_mean_absolute_error: 0.2879\n",
      "Epoch 48/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1808 - mean_absolute_error: 0.3031 - val_loss: 0.1934 - val_mean_absolute_error: 0.2878\n",
      "Epoch 49/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1807 - mean_absolute_error: 0.3030 - val_loss: 0.1931 - val_mean_absolute_error: 0.2877\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1806 - mean_absolute_error: 0.3029 - val_loss: 0.1928 - val_mean_absolute_error: 0.2876\n",
      "Epoch 51/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1804 - mean_absolute_error: 0.3027 - val_loss: 0.1925 - val_mean_absolute_error: 0.2875\n",
      "Epoch 52/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1803 - mean_absolute_error: 0.3026 - val_loss: 0.1923 - val_mean_absolute_error: 0.2874\n",
      "Epoch 53/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1802 - mean_absolute_error: 0.3025 - val_loss: 0.1920 - val_mean_absolute_error: 0.2872\n",
      "Epoch 54/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1801 - mean_absolute_error: 0.3024 - val_loss: 0.1918 - val_mean_absolute_error: 0.2871\n",
      "Epoch 55/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1800 - mean_absolute_error: 0.3022 - val_loss: 0.1915 - val_mean_absolute_error: 0.2869\n",
      "Epoch 56/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1799 - mean_absolute_error: 0.3021 - val_loss: 0.1913 - val_mean_absolute_error: 0.2868\n",
      "Epoch 57/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1798 - mean_absolute_error: 0.3020 - val_loss: 0.1911 - val_mean_absolute_error: 0.2866\n",
      "Epoch 58/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1797 - mean_absolute_error: 0.3019 - val_loss: 0.1909 - val_mean_absolute_error: 0.2864\n",
      "Epoch 59/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1796 - mean_absolute_error: 0.3018 - val_loss: 0.1907 - val_mean_absolute_error: 0.2863\n",
      "Epoch 60/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1795 - mean_absolute_error: 0.3017 - val_loss: 0.1906 - val_mean_absolute_error: 0.2861\n",
      "Epoch 61/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1794 - mean_absolute_error: 0.3016 - val_loss: 0.1904 - val_mean_absolute_error: 0.2859\n",
      "Epoch 62/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1794 - mean_absolute_error: 0.3015 - val_loss: 0.1902 - val_mean_absolute_error: 0.2857\n",
      "Epoch 63/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1793 - mean_absolute_error: 0.3014 - val_loss: 0.1901 - val_mean_absolute_error: 0.2855\n",
      "Epoch 64/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1792 - mean_absolute_error: 0.3013 - val_loss: 0.1900 - val_mean_absolute_error: 0.2854\n",
      "Epoch 65/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1791 - mean_absolute_error: 0.3012 - val_loss: 0.1898 - val_mean_absolute_error: 0.2852\n",
      "Epoch 66/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1791 - mean_absolute_error: 0.3012 - val_loss: 0.1897 - val_mean_absolute_error: 0.2850\n",
      "Epoch 67/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1790 - mean_absolute_error: 0.3011 - val_loss: 0.1896 - val_mean_absolute_error: 0.2848\n",
      "Epoch 68/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1789 - mean_absolute_error: 0.3010 - val_loss: 0.1895 - val_mean_absolute_error: 0.2847\n",
      "Epoch 69/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1788 - mean_absolute_error: 0.3009 - val_loss: 0.1894 - val_mean_absolute_error: 0.2845\n",
      "Epoch 70/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1787 - mean_absolute_error: 0.3009 - val_loss: 0.1893 - val_mean_absolute_error: 0.2843\n",
      "Epoch 71/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1787 - mean_absolute_error: 0.3008 - val_loss: 0.1892 - val_mean_absolute_error: 0.2841\n",
      "Epoch 72/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1786 - mean_absolute_error: 0.3007 - val_loss: 0.1891 - val_mean_absolute_error: 0.2840\n",
      "Epoch 73/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1785 - mean_absolute_error: 0.3006 - val_loss: 0.1890 - val_mean_absolute_error: 0.2838\n",
      "Epoch 74/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1784 - mean_absolute_error: 0.3005 - val_loss: 0.1889 - val_mean_absolute_error: 0.2836\n",
      "Epoch 75/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1783 - mean_absolute_error: 0.3005 - val_loss: 0.1888 - val_mean_absolute_error: 0.2835\n",
      "Epoch 76/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1783 - mean_absolute_error: 0.3004 - val_loss: 0.1887 - val_mean_absolute_error: 0.2833\n",
      "Epoch 77/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1782 - mean_absolute_error: 0.3003 - val_loss: 0.1885 - val_mean_absolute_error: 0.2832\n",
      "Epoch 78/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1781 - mean_absolute_error: 0.3002 - val_loss: 0.1884 - val_mean_absolute_error: 0.2830\n",
      "Epoch 79/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1780 - mean_absolute_error: 0.3001 - val_loss: 0.1883 - val_mean_absolute_error: 0.2829\n",
      "Epoch 80/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1779 - mean_absolute_error: 0.3001 - val_loss: 0.1882 - val_mean_absolute_error: 0.2827\n",
      "Epoch 81/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1778 - mean_absolute_error: 0.3000 - val_loss: 0.1881 - val_mean_absolute_error: 0.2826\n",
      "Epoch 82/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1778 - mean_absolute_error: 0.2999 - val_loss: 0.1880 - val_mean_absolute_error: 0.2824\n",
      "Epoch 83/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1777 - mean_absolute_error: 0.2998 - val_loss: 0.1879 - val_mean_absolute_error: 0.2823\n",
      "Epoch 84/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1776 - mean_absolute_error: 0.2997 - val_loss: 0.1878 - val_mean_absolute_error: 0.2821\n",
      "Epoch 85/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1775 - mean_absolute_error: 0.2997 - val_loss: 0.1876 - val_mean_absolute_error: 0.2820\n",
      "Epoch 86/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1774 - mean_absolute_error: 0.2996 - val_loss: 0.1875 - val_mean_absolute_error: 0.2818\n",
      "Epoch 87/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1773 - mean_absolute_error: 0.2995 - val_loss: 0.1874 - val_mean_absolute_error: 0.2817\n",
      "Epoch 88/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1772 - mean_absolute_error: 0.2994 - val_loss: 0.1873 - val_mean_absolute_error: 0.2816\n",
      "Epoch 89/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1771 - mean_absolute_error: 0.2993 - val_loss: 0.1872 - val_mean_absolute_error: 0.2814\n",
      "Epoch 90/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1771 - mean_absolute_error: 0.2993 - val_loss: 0.1870 - val_mean_absolute_error: 0.2813\n",
      "Epoch 91/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1770 - mean_absolute_error: 0.2992 - val_loss: 0.1869 - val_mean_absolute_error: 0.2812\n",
      "Epoch 92/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1769 - mean_absolute_error: 0.2991 - val_loss: 0.1868 - val_mean_absolute_error: 0.2811\n",
      "Epoch 93/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1768 - mean_absolute_error: 0.2991 - val_loss: 0.1867 - val_mean_absolute_error: 0.2810\n",
      "Epoch 94/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1767 - mean_absolute_error: 0.2990 - val_loss: 0.1866 - val_mean_absolute_error: 0.2809\n",
      "Epoch 95/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1767 - mean_absolute_error: 0.2989 - val_loss: 0.1865 - val_mean_absolute_error: 0.2808\n",
      "Epoch 96/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1766 - mean_absolute_error: 0.2989 - val_loss: 0.1864 - val_mean_absolute_error: 0.2807\n",
      "Epoch 97/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1765 - mean_absolute_error: 0.2988 - val_loss: 0.1863 - val_mean_absolute_error: 0.2806\n",
      "Epoch 98/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1765 - mean_absolute_error: 0.2987 - val_loss: 0.1862 - val_mean_absolute_error: 0.2805\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1764 - mean_absolute_error: 0.2987 - val_loss: 0.1861 - val_mean_absolute_error: 0.2804\n",
      "Epoch 100/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1763 - mean_absolute_error: 0.2986 - val_loss: 0.1860 - val_mean_absolute_error: 0.2803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fabebc42280>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "                # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "                tf.keras.layers.LSTM(64, return_sequences=True, activation=\"tanh\"),\n",
    "                # Shape => [batch, time, features]\n",
    "                tf.keras.layers.Dense(units=1)\n",
    "            ])\n",
    "\n",
    "compile_and_fit(lstm_model, cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b08fc33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy (kw 15min)</th>\n",
       "      <th>cluster energy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-02 00:00:00</th>\n",
       "      <td>-0.774395</td>\n",
       "      <td>-0.238993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02 01:00:00</th>\n",
       "      <td>-0.829437</td>\n",
       "      <td>-0.333230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02 02:00:00</th>\n",
       "      <td>-0.847784</td>\n",
       "      <td>-0.359083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02 03:00:00</th>\n",
       "      <td>-0.847784</td>\n",
       "      <td>0.096259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02 04:00:00</th>\n",
       "      <td>-0.829437</td>\n",
       "      <td>-0.056356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 19:00:00</th>\n",
       "      <td>-0.187287</td>\n",
       "      <td>-0.442108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 20:00:00</th>\n",
       "      <td>-0.425800</td>\n",
       "      <td>-0.837591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 21:00:00</th>\n",
       "      <td>-0.352411</td>\n",
       "      <td>-0.995580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 22:00:00</th>\n",
       "      <td>-0.444147</td>\n",
       "      <td>-1.057757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 23:00:00</th>\n",
       "      <td>-0.499188</td>\n",
       "      <td>-1.142357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4104 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     energy (kw 15min)  cluster energy\n",
       "Date Time                                             \n",
       "2018-04-02 00:00:00          -0.774395       -0.238993\n",
       "2018-04-02 01:00:00          -0.829437       -0.333230\n",
       "2018-04-02 02:00:00          -0.847784       -0.359083\n",
       "2018-04-02 03:00:00          -0.847784        0.096259\n",
       "2018-04-02 04:00:00          -0.829437       -0.056356\n",
       "...                                ...             ...\n",
       "2018-09-19 19:00:00          -0.187287       -0.442108\n",
       "2018-09-19 20:00:00          -0.425800       -0.837591\n",
       "2018-09-19 21:00:00          -0.352411       -0.995580\n",
       "2018-09-19 22:00:00          -0.444147       -1.057757\n",
       "2018-09-19 23:00:00          -0.499188       -1.142357\n",
       "\n",
       "[4104 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_test_df = nad['test']\n",
    "cluster_time_series = pd.DataFrame(columns=['energy (kw 15min)'])\n",
    "\n",
    "for idx in range(0,len(cluster_test_df), 24):\n",
    "    in_pd = pd.DataFrame(columns=['energy (kw 15min)'])\n",
    "    index = cluster_test_df.iloc[idx: idx+24].index\n",
    "    \n",
    "    season = get_season(index[0].month)\n",
    "    weekday = index[0].weekday()\n",
    "    label = cluster_dist_dict[season][weekday]\n",
    "    c_pattern = cluster_norm_dict[season].iloc[label].values\n",
    "    \n",
    "    for idx, _ in enumerate(index):\n",
    "        in_pd.loc[_] = c_pattern[idx]\n",
    "        \n",
    "    cluster_time_series = pd.concat([cluster_time_series, in_pd])\n",
    "\n",
    "cluster_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d4f6ca8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy (kw 15min)</th>\n",
       "      <th>cluster energy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-02 00:00:00</th>\n",
       "      <td>-0.774395</td>\n",
       "      <td>-0.238993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02 01:00:00</th>\n",
       "      <td>-0.829437</td>\n",
       "      <td>-0.333230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02 02:00:00</th>\n",
       "      <td>-0.847784</td>\n",
       "      <td>-0.359083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02 03:00:00</th>\n",
       "      <td>-0.847784</td>\n",
       "      <td>0.096259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02 04:00:00</th>\n",
       "      <td>-0.829437</td>\n",
       "      <td>-0.056356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 19:00:00</th>\n",
       "      <td>-0.187287</td>\n",
       "      <td>-0.442108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 20:00:00</th>\n",
       "      <td>-0.425800</td>\n",
       "      <td>-0.837591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 21:00:00</th>\n",
       "      <td>-0.352411</td>\n",
       "      <td>-0.995580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 22:00:00</th>\n",
       "      <td>-0.444147</td>\n",
       "      <td>-1.057757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 23:00:00</th>\n",
       "      <td>-0.499188</td>\n",
       "      <td>-1.142357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4104 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     energy (kw 15min)  cluster energy\n",
       "Date Time                                             \n",
       "2018-04-02 00:00:00          -0.774395       -0.238993\n",
       "2018-04-02 01:00:00          -0.829437       -0.333230\n",
       "2018-04-02 02:00:00          -0.847784       -0.359083\n",
       "2018-04-02 03:00:00          -0.847784        0.096259\n",
       "2018-04-02 04:00:00          -0.829437       -0.056356\n",
       "...                                ...             ...\n",
       "2018-09-19 19:00:00          -0.187287       -0.442108\n",
       "2018-09-19 20:00:00          -0.425800       -0.837591\n",
       "2018-09-19 21:00:00          -0.352411       -0.995580\n",
       "2018-09-19 22:00:00          -0.444147       -1.057757\n",
       "2018-09-19 23:00:00          -0.499188       -1.142357\n",
       "\n",
       "[4104 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_test_df['cluster energy'] = cluster_time_series['energy (kw 15min)']\n",
    "cluster_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b8563084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicts_list = np.array([])\n",
    "original_list = np.array([])\n",
    "test_df = cluster_test_df.copy()\n",
    "for _ in range(0, round(len(test_df) / 24), 50):\n",
    "    test_df = cluster_test_df[_ * 24:(_ + 50) * 24]\n",
    "    \n",
    "    feature_length = 2\n",
    "    predict_data_length = 3\n",
    "#     fig, axes = plt.subplots(math.ceil(round(len(test_df) / 24) / 5),5, figsize=(30,30))\n",
    "#     ax = plt.gca()\n",
    "#     ax.axes.xaxis.set_visible(False)\n",
    "#     ax.axes.yaxis.set_visible(False)\n",
    "    cnt = 0\n",
    "\n",
    "    for split in range(0, round(len(test_df)), 24):\n",
    "        original_x_labels = [idx for idx in range(1,25)]\n",
    "        predict_x_labels  = [idx for idx in range((predict_data_length + 1), 25)]\n",
    "        original = test_df[split:(split + 24)]['energy (kw 15min)'].values.flatten()\n",
    "\n",
    "        date = test_df[split:(split + 24)].index[0]\n",
    "        season = get_season(date.month)\n",
    "        weekday = date.weekday()\n",
    "        label = cluster_dist_dict[season][weekday]\n",
    "        c_pattern = cluster_norm_dict[season].loc[label].values\n",
    "\n",
    "        predicts = []\n",
    "        inputs = []\n",
    "\n",
    "        for idx in range(0, (24 - predict_data_length)):\n",
    "            inputs = test_df[split:(split + 24)].values[idx:predict_data_length + idx].flatten()\n",
    "            inputs = inputs.reshape(-1, predict_data_length, feature_length)\n",
    "            result = lstm_model(inputs).numpy().flatten()[2]\n",
    "\n",
    "            predicts.append(result)\n",
    "            inputs = np.append(inputs.flatten()[1:predict_data_length],result)\n",
    "            \n",
    "        predicts_list = np.append(predicts_list, predicts)\n",
    "        original_list = np.append(original_list, original[3:])\n",
    "\n",
    "#         sns.lineplot(original_x_labels, original, lw=2, ax=axes[\n",
    "#             math.floor(cnt / 5)\n",
    "#         ][math.floor(cnt % 5)])\n",
    "#         sns.lineplot(predict_x_labels, predicts, lw=3, ax=axes[\n",
    "#             math.floor(cnt / 5)\n",
    "#         ][math.floor(cnt % 5)])\n",
    "#         sns.lineplot(original_x_labels, c_pattern, lw=3, ax=axes[\n",
    "#             math.floor(cnt / 5)\n",
    "#         ][math.floor(cnt % 5)])\n",
    "\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2e67efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss is 1456.9100393977487, wss is 3568.1966976425047, mean dis is 3.9987579243325984, mean sim is 0.4528471517959315, ecv is -144.91537577141762%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecv</th>\n",
       "      <th>mean dis</th>\n",
       "      <th>mean sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cluster pattern</th>\n",
       "      <td>-144.915376</td>\n",
       "      <td>3.998758</td>\n",
       "      <td>0.452847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ecv  mean dis  mean sim\n",
       "cluster pattern -144.915376  3.998758  0.452847"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean as euc\n",
    "\n",
    "def cos_sim(A, B):\n",
    "    return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "test_df = pd.DataFrame(norm_all_dict['univariate']['test']['energy (kw 15min)'].copy())\n",
    "test_df\n",
    "\n",
    "col_test_df = pd.DataFrame()\n",
    "for idx in range(0, len(test_df), 24):\n",
    "    date = test_df.iloc[idx:].index[0]\n",
    "    col_test_df[date] = test_df.iloc[idx: idx+24]['energy (kw 15min)'].values\n",
    "    \n",
    "mean_pattern = col_test_df.mean(axis=1)\n",
    "\n",
    "# calc tss, calc wss (only test data)\n",
    "tss = 0\n",
    "wss = 0\n",
    "cluster_distance = np.array([])\n",
    "cluster_similarity = np.array([])\n",
    "for idx in range(0, len(test_df), 24):\n",
    "    # calc tss\n",
    "    pattern_df = test_df.iloc[idx: idx+24].copy()\n",
    "    pattern = pattern_df.values.flatten()\n",
    "    tss += euc(\n",
    "        mean_pattern[3:],\n",
    "        pattern[3:]\n",
    "    ) ** 2\n",
    "    \n",
    "    # calc wss\n",
    "    date = pattern_df.index[0]\n",
    "    season = get_season(date.month)\n",
    "    weekday = date.weekday()\n",
    "    label = cluster_dist_dict[season][weekday]\n",
    "    \n",
    "    c_pattern = cluster_norm_dict[season].loc[label].values\n",
    "    wss += euc(\n",
    "        c_pattern[3:],\n",
    "        pattern[3:]\n",
    "    ) ** 2\n",
    "    \n",
    "    distance = euc(\n",
    "        c_pattern[3:],\n",
    "        pattern[3:]\n",
    "    )\n",
    "    similarity = cos_sim(\n",
    "        c_pattern[3:],\n",
    "        pattern[3:]\n",
    "    )\n",
    "    \n",
    "    cluster_distance = np.append(cluster_distance, [distance])\n",
    "    cluster_similarity = np.append(cluster_similarity, [similarity])\n",
    "    \n",
    "mean_dis = cluster_distance.mean()\n",
    "mean_sim = cluster_similarity.mean()\n",
    "cluster_ecv = (1 - (wss / tss)) * 100\n",
    "print(\"tss is {}, wss is {}, mean dis is {}, mean sim is {}, ecv is {}%\".format(tss, wss, mean_dis, mean_sim, cluster_ecv))\n",
    "\n",
    "evaluate_df = pd.DataFrame(columns=['ecv', 'mean dis', 'mean sim'])\n",
    "evaluate_df.loc['cluster pattern'] = [\n",
    "    cluster_ecv,\n",
    "    mean_dis,\n",
    "    mean_sim\n",
    "]\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "204587d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3591"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b653ce50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3591"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c534dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_list = predicts_list.reshape(-1,21)\n",
    "original_list = original_list.reshape(-1,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a669d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "wss = 0\n",
    "distances = list()\n",
    "similarities = list()\n",
    "\n",
    "for idx, p_pattern in enumerate(predicts_list):\n",
    "    o_pattern = original_list[idx]\n",
    "    \n",
    "    wss += euc(\n",
    "        p_pattern,\n",
    "        o_pattern\n",
    "    ) ** 2\n",
    "    \n",
    "    distances.append(\n",
    "        euc(\n",
    "            p_pattern,\n",
    "            o_pattern\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    similarities.append(\n",
    "        cos_sim(\n",
    "            p_pattern,\n",
    "            o_pattern\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b4629a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_df.loc['with cluster'] = [\n",
    "        (1 - (wss / tss)) * 100,\n",
    "        np.array(distances).mean(),\n",
    "        np.array(similarities).mean()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bb4d4a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecv</th>\n",
       "      <th>mean dis</th>\n",
       "      <th>mean sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cluster pattern</th>\n",
       "      <td>-144.915376</td>\n",
       "      <td>3.998758</td>\n",
       "      <td>0.452847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with cluster</th>\n",
       "      <td>82.638652</td>\n",
       "      <td>1.144908</td>\n",
       "      <td>0.949205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ecv  mean dis  mean sim\n",
       "cluster pattern -144.915376  3.998758  0.452847\n",
       "with cluster      82.638652  1.144908  0.949205"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
